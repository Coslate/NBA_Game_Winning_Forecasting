{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Final Project - NBA Game Winning Forecasting\n",
    "## Game Prediction - Future Game Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - featureEng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param X: pandas.DataFrame\n",
    "# @param featureSel: int\n",
    "# @return X: pandas.DataFrame\n",
    "def featureEng(X, featureSel=None):\n",
    "    # Feature Engineering\n",
    "    if not featureSel or featureSel == 0:\n",
    "        return X\n",
    "    if featureSel == 1:\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "    elif featureSel == 2:\n",
    "        attriToDrop = ['PTS_A', 'PTS_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    elif featureSel == 3:\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "        attriToDrop = ['PTS_A', 'PTS_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    elif featureSel == 4:\n",
    "        attriToDrop = [\n",
    "            'FGM_A', 'FGA_A', '3PM_A', '3PA_A', 'FTM_A', 'FTA_A', 'OREB_A', 'DREB_A', 'PF_A', \n",
    "            'FGM_B', 'FGA_B', '3PM_B', '3PA_B', 'FTM_B', 'FTA_B', 'OREB_B', 'DREB_B', 'PF_B'\n",
    "        ]\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "        X['STL+BLK_A'] = X['STL_A'] + X['BLK_A']\n",
    "        X['STL+BLK_B'] = X['STL_B'] + X['BLK_B']\n",
    "        attriToDrop += ['PTS_A', 'PTS_B', 'STL_A', 'STL_B', 'BLK_A', 'BLK_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - featureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int\n",
    "# @param featureSel: int\n",
    "# @return X, Y: pandas.DataFrame\n",
    "# featureExtraction() outputs X, Y for model training.\n",
    "def featureExtraction(dfFile, dateStart='1000-01-01', dateEnd='2999-12-31', period=5, featureSel=None):\n",
    "    df = pd.read_csv(dfFile)\n",
    "    \n",
    "    # Date selection\n",
    "    df = df.loc[(df.Date_A >= dateStart) & (df.Date_A <= dateEnd), :].reset_index(drop=True)\n",
    "    \n",
    "    # Get label Y\n",
    "    Y = df[['W/L_A']]\n",
    "    Y = Y.rename(columns={'W/L_A': 'Label'})\n",
    "    \n",
    "    # Get averaged attributes X\n",
    "    for idx, row in df.iterrows():\n",
    "        df_sel = df.loc[df.Date_A <= row['Date_A'], :].reset_index(drop=True)\n",
    "        \n",
    "        # Process of Team_A\n",
    "        gamePlayed_A = df_sel.loc[df_sel.Team_A == row['Team_A'], :]\n",
    "        if len(gamePlayed_A) == 1:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[0:1, 0:24].reset_index(drop=True)\n",
    "        elif len(gamePlayed_A) < period:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:len(gamePlayed_A), 0:24].reset_index(drop=True)\n",
    "        else:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:period+1, 0:24].reset_index(drop=True)\n",
    "        \n",
    "        # Process of Team_B\n",
    "        gamePlayed_B = df_sel.loc[df_sel.Team_A == row['Team_B'], :]\n",
    "        if len(gamePlayed_B) == 1:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[0:1, 0:24].reset_index(drop=True)\n",
    "        elif len(gamePlayed_B) < period:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:len(gamePlayed_B), 0:24].reset_index(drop=True)\n",
    "        else:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:period+1, 0:24].reset_index(drop=True)\n",
    "        \n",
    "        # Drop unnecessary attributes\n",
    "        colToDrop = ['Home/Away_A'] + ['Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A']\n",
    "        X_A = X_A.drop(columns=colToDrop)\n",
    "        X_B = X_B.drop(columns=colToDrop)\n",
    "        \n",
    "        # Rename X_B's columns\n",
    "        X_B = X_B.rename(columns=lambda x: x[0:-2] + '_B')\n",
    "        \n",
    "        # Get X_single = [Home/Away_A + X_A + X_B]\n",
    "        X_single = pd.DataFrame(data=pd.concat([X_A.mean(), X_B.mean()])).transpose()\n",
    "        X_single = pd.concat([pd.DataFrame(data={'Home/Away_A': [row['Home/Away_A']]}), X_single], axis=1)\n",
    "        \n",
    "        # Concatenation dataFrames by row\n",
    "        if idx == 0:\n",
    "            X = X_single\n",
    "        else:\n",
    "            X = pd.concat([X, X_single], ignore_index=True)\n",
    "        \n",
    "    # Feature Engineering\n",
    "    X = featureEng(X, featureSel)\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - attriGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame (from 'nba_preprocessed.csv')\n",
    "# @param date: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int (Number of previous games to be considered)\n",
    "# @param Team_A, Team_B: str\n",
    "# @param homeAway: int (None for played game prediction)\n",
    "# @param featureSel: int\n",
    "# @return X: pandas.DataFrame\n",
    "def attriGen(df, date, period, Team_A, Team_B, homeAway=None, featureSel=None):\n",
    "    # True Home/Away at the game day\n",
    "    if homeAway is None:\n",
    "        df_gameDay = df.loc[(df.Date_A == date) & (df.Team_A == Team_A) & (df.Team_B == Team_B), :].reset_index(drop=True)\n",
    "        homeAway = int(df_gameDay['Home/Away_A'])\n",
    "    \n",
    "    # Date selections\n",
    "    df = df.loc[df.Date_A < date, :].reset_index(drop=True)\n",
    "    X_A = df.loc[(df.Team_A == Team_A), :].sort_values(by=['Date_A'], ascending=False).iloc[0:period, 0:24].reset_index(drop=True)\n",
    "    X_B = df.loc[(df.Team_A == Team_B), :].sort_values(by=['Date_A'], ascending=False).iloc[0:period, 0:24].reset_index(drop=True)\n",
    "    \n",
    "    # Drop unnecessary attributes\n",
    "    colToDrop = ['Home/Away_A'] + ['Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A']\n",
    "    X_A = X_A.drop(columns=colToDrop)\n",
    "    X_B = X_B.drop(columns=colToDrop)\n",
    "    \n",
    "    # Rename X_away's columns\n",
    "    X_B = X_B.rename(columns=lambda x: x[0:-2] + '_B')\n",
    "    \n",
    "    # Get X = [Home/Away_A + X_A + X_B]\n",
    "    X = pd.DataFrame(data=pd.concat([X_A.mean(), X_B.mean()])).transpose()\n",
    "    X = pd.concat([pd.DataFrame(data={'Home/Away_A': [homeAway]}), X], axis=1)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    X = featureEng(X, featureSel)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - groundTruthGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame (from 'nba_preprocessed.csv')\n",
    "# @param date: str in the format of 'YYYY-MM-DD'\n",
    "# @param Team_A, Team_B: str\n",
    "# @param featureSel: int\n",
    "# @return X_groundTruth, Y_groundTruth: pandas.DataFrame\n",
    "def groundTruthGen(df, date, Team_A, Team_B, featureSel=None):\n",
    "    # Date selections\n",
    "    df = df.loc[(df.Date_A == date) & (df.Team_A == Team_A) & (df.Team_B == Team_B), :].reset_index(drop=True)\n",
    "\n",
    "    # Get label Y\n",
    "    Y_groundTruth = df[['W/L_A']]\n",
    "    Y_groundTruth = Y_groundTruth.rename(columns={'W/L_A': 'Label'})\n",
    "    \n",
    "    # Drop unnecessary attributes\n",
    "    colToDrop = [\n",
    "        'Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A', \n",
    "        'Team_B', 'Date_B', 'W/L_B', 'Home/Away_B', 'Score_B', 'Opponent_B'\n",
    "    ]\n",
    "    X_groundTruth = df.drop(columns=colToDrop)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    X_groundTruth = featureEng(X_groundTruth, featureSel)\n",
    "    \n",
    "    return X_groundTruth, Y_groundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - gameAttriGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int\n",
    "# @param Team_A, Team_B: str (If both are None, predict all games within the date range)\n",
    "# @param featureSel: int\n",
    "# @return X, Y: pandas.DataFrame\n",
    "# gameAttriGen() outputs X_attri, Y_truth for game prediction.\n",
    "def gameAttriGen(dfFile, dateStart, dateEnd, period=5, Team_A=None, Team_B=None, featureSel=None):\n",
    "    df = pd.read_csv(dfFile)\n",
    "    \n",
    "    # Date selections\n",
    "    df_sel = df.loc[(df.Date_A >= dateStart) & (df.Date_A <= dateEnd), :].reset_index(drop=True)\n",
    "    \n",
    "    # Generate df_sel which includes [date, Team_A, Team_B] columns\n",
    "    if Team_A and Team_B:\n",
    "        df_sel = df_sel.loc[(df_sel.Team_A == Team_A) & (df_sel.Opponent_A == Team_B), :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif Team_A and not Team_B:\n",
    "        df_sel = df_sel.loc[df_sel.Team_A == Team_A, :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif not Team_A and Team_B:\n",
    "        df_sel = df_sel.loc[df_sel.Opponent_A == Team_B, :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif not Team_A and not Team_B:\n",
    "        df_sel = df_sel[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "        # Delete duplicates: (Team_A vs Team_B) is the same as (Team_B vs Team_A). Remove one to avoid double count.\n",
    "        df_new = pd.DataFrame(columns=['Date_A', 'Team_A', 'Opponent_A'])\n",
    "        LUT = {}\n",
    "        for date, x, y in zip(df_sel['Date_A'], df_sel['Team_A'], df_sel['Opponent_A']):\n",
    "            if (date + x + y) in LUT:\n",
    "                df_new = pd.concat([df_new, pd.DataFrame(columns=['Date_A', 'Team_A', 'Opponent_A'], data=[[date, x, y]])], ignore_index=True)\n",
    "            else:\n",
    "                LUT[date + x + y] = 1\n",
    "                LUT[date + y + x] = 1\n",
    "        df_sel = df_new\n",
    "    \n",
    "    # W/L prediction\n",
    "    X_attri = Y_truth = None\n",
    "    for date, Team_A, Team_B in zip(df_sel['Date_A'], df_sel['Team_A'], df_sel['Opponent_A']):\n",
    "        X_toBePredicted = attriGen(df, date, period, Team_A, Team_B, None, featureSel)\n",
    "        X_groundTruth, Y_groundTruth = groundTruthGen(df, date, Team_A, Team_B, featureSel)\n",
    "        if X_attri is None and Y_truth is None:\n",
    "            X_attri = X_toBePredicted\n",
    "            Y_truth = Y_groundTruth\n",
    "        else:\n",
    "            X_attri = pd.concat([X_attri, X_toBePredicted], ignore_index=True)\n",
    "            Y_truth = pd.concat([Y_truth, Y_groundTruth], ignore_index=True)\n",
    "        \n",
    "    return X_attri, Y_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - gamePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param modelsLUT: dict in the format of {'modelName': model}\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int (Number of previous games to be considered)\n",
    "# @param Team_A, Team_B: str (If both are None, predict all games within the date range)\n",
    "# @param featureSel: int\n",
    "# @return None\n",
    "# gamePrediction() prints the predicted game W/L results.\n",
    "def gamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period=5, Team_A=None, Team_B=None, featureSel=None):\n",
    "    X_attri, Y_truth = gameAttriGen(dfFile, dateStart, dateEnd, period, Team_A, Team_B, featureSel)\n",
    "    \n",
    "    resultLUT, accuLUT = {}, {}\n",
    "    for model in modelsLUT:\n",
    "        resultLUT[model] = modelsLUT[model].predict(X_attri)\n",
    "        accuLUT[model] = accuracy_score(Y_truth, modelsLUT[model].predict(X_attri))\n",
    "    \n",
    "    print('---------- Prediction Accuracy ----------')\n",
    "    print('featureSel =', featureSel)\n",
    "    for x in accuLUT:\n",
    "        print(x, '=', accuLUT[x]*100, '%')\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - votingGamePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def votingGamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period=5, Team_A=None, Team_B=None, featureSel=None, isReport=False):\n",
    "    X_attri, Y_truth = gameAttriGen(dfFile, dateStart, dateEnd, period, Team_A, Team_B, featureSel)\n",
    "    numGame = len(Y_truth)\n",
    "    \n",
    "    resultLUT, accuLUT, maxAccuracy = {}, {}, 0\n",
    "    for model in modelsLUT:\n",
    "        resultLUT[model] = modelsLUT[model].predict(X_attri)\n",
    "        accuLUT[model] = accuracy_score(Y_truth, modelsLUT[model].predict(X_attri))\n",
    "        if accuLUT[model] > maxAccuracy:\n",
    "            maxAccuracy = accuLUT[model]\n",
    "            bestModel = model\n",
    "    \n",
    "    finalVote = []\n",
    "    for i in range(0, numGame):\n",
    "        voteForWin, voteForLoss = 0, 0\n",
    "        for model in resultLUT:\n",
    "            if resultLUT[model][i] == 1:\n",
    "                voteForWin += 1\n",
    "            else:\n",
    "                voteForLoss += 1\n",
    "        if voteForWin > voteForLoss:\n",
    "            finalVote.append(1)\n",
    "        elif voteForWin < voteForLoss:\n",
    "            finalVote.append(0)\n",
    "        else:\n",
    "            finalVote.append(resultLUT[bestModel][i])\n",
    "        if isReport == True:\n",
    "            print(f'Y_predict={finalVote[i]}(voteForLoss={voteForLoss}, voteForWin={voteForWin}), Y_truth={Y_truth[\"Label\"][i]}')\n",
    "    \n",
    "    finalAccuracy = accuracy_score(Y_truth, finalVote)\n",
    "    print(f'Number of games = {numGame}')\n",
    "    print(f'Number of models = {len(resultLUT)}')\n",
    "    print('---------- Prediction Accuracy ----------')\n",
    "    print(f'Best Model = {bestModel} w/ the accuracy of {accuLUT[bestModel]*100} %')\n",
    "    print(f'Prediction Accuracy by voting = {finalAccuracy*100} %')\n",
    "    print('------------------------------------')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function - futureGamePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def futureGamePrediction(dfFile, modelsLUT, date, period, Team_A, Team_B, homeAway, featureSel):\n",
    "    df = pd.read_csv(dfFile)\n",
    "    df_sel = df.loc[df.Date_A == date, :].reset_index(drop=True)\n",
    "\n",
    "    if df_sel.empty and (homeAway is None):\n",
    "        print(f'Error: Game not found and Home/Away is not defined.')\n",
    "        print(f'isEmpty = {df_sel.empty}, HomeAway = {homeAway}')\n",
    "        print('Force return w/o actions.')\n",
    "        return None\n",
    "    \n",
    "    # Generate the attributes\n",
    "    X_toBePredicted = attriGen(df, date, period, Team_A, Team_B, homeAway, featureSel)\n",
    "    \n",
    "    # Game prediction\n",
    "    resultLUT = {}\n",
    "    for model in modelsLUT:\n",
    "        resultLUT[model] = modelsLUT[model].predict(X_toBePredicted)\n",
    "    \n",
    "    # Generate prediction report\n",
    "    predictList = [resultLUT[x][0] for x in resultLUT]\n",
    "    voteForWin = sum(predictList)\n",
    "    voteForLoss = len(predictList) - voteForWin\n",
    "    col = ['Date', 'Home/Away_A', 'Team_A', 'Team_B'] + list(resultLUT.keys()) + ['Vote for Win', 'Vote for Loss']\n",
    "    data = [date, homeAway, Team_A, Team_B] + predictList + [voteForWin, voteForLoss] \n",
    "    df_report = pd.DataFrame([data], columns=col)\n",
    "    \n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2015-08-01'\n",
    "dateEnd = '2018-04-13'\n",
    "period = 5\n",
    "featureSel = 3\n",
    "X, Y = featureExtraction(dfFile, dateStart, dateEnd, period, featureSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logistic Regression ...\n",
      ">> SVM ...\n",
      ">> XGBoost ...\n",
      ">> Naive Bayes ...\n",
      ">> Random Forest ...\n",
      ">> GBDT ...\n",
      ">> LightGBM ...\n",
      ">> AdaBoost ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.1, n_estimators=1000, random_state=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "print('>> Logistic Regression ...')\n",
    "logiRegr = LogisticRegression()\n",
    "logiRegr.fit(X, Y)\n",
    "logiRegrCVGS = LogisticRegression(C=100, max_iter=400)\n",
    "logiRegrCVGS.fit(X, Y)\n",
    "\n",
    "print('>> SVM ...')\n",
    "supVecMachine = SVC(kernel='linear', probability=True)\n",
    "supVecMachine.fit(X, Y)\n",
    "supVecMachineCVGS = SVC(C=10, kernel='linear', probability=True)\n",
    "supVecMachineCVGS.fit(X, Y)\n",
    "\n",
    "print('>> XGBoost ...')\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X, Y)\n",
    "xgbcCVGS = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, min_child_weight=3, gamma=0.2)\n",
    "xgbcCVGS.fit(X, Y)\n",
    "\n",
    "print('>> Naive Bayes ...')\n",
    "naiveBayes = GaussianNB()\n",
    "naiveBayes.fit(X, Y)\n",
    "\n",
    "print('>> Random Forest ...')\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest.fit(X, Y)\n",
    "randomForestCVGS = RandomForestClassifier(n_estimators=600, criterion='entropy', bootstrap=True, max_depth=None, max_features='sqrt')\n",
    "randomForestCVGS.fit(X, Y)\n",
    "\n",
    "print('>> GBDT ...')\n",
    "gbdt = GradientBoostingClassifier()\n",
    "gbdt.fit(X,Y)\n",
    "gbdtCVGS = GradientBoostingClassifier(loss='exponential', n_estimators=600, learning_rate=0.1, max_depth=3, subsample=0.5, max_features='sqrt')\n",
    "gbdtCVGS.fit(X,Y)\n",
    "\n",
    "print('>> LightGBM ...')\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X, Y)\n",
    "lgbmCVGS = LGBMClassifier(learning_rate=0.1, n_estimators=800, max_depth=-1, subsample=0.5)\n",
    "lgbmCVGS.fit(X, Y)\n",
    "\n",
    "print('>> AdaBoost ...')\n",
    "adaBoost = AdaBoostClassifier()\n",
    "adaBoost.fit(X, Y)\n",
    "adaBoostCVGS = AdaBoostClassifier(learning_rate=0.1, n_estimators=1000)\n",
    "adaBoostCVGS.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsLUT = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'logiRegrCVGS': logiRegrCVGS,\n",
    "    'supVecMachine': supVecMachine,\n",
    "    'supVecMachineCVGS': supVecMachineCVGS,\n",
    "    'xgbc': xgbc,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'naiveBayes': naiveBayes,\n",
    "    'randomForest': randomForest,\n",
    "    'randomForestCVGS': randomForestCVGS,\n",
    "    'gbdt': gbdt,\n",
    "    'gbdtCVGS': gbdtCVGS,\n",
    "    'lgbm': lgbm,\n",
    "    'lgbmCVGS': lgbmCVGS, \n",
    "    'adaBoost': adaBoost,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Prediction Accuracy ----------\n",
      "featureSel = 3\n",
      "logiRegr = 71.95121951219512 %\n",
      "logiRegrCVGS = 70.73170731707317 %\n",
      "supVecMachine = 75.60975609756098 %\n",
      "supVecMachineCVGS = 73.17073170731707 %\n",
      "xgbc = 73.17073170731707 %\n",
      "xgbcCVGS = 75.60975609756098 %\n",
      "naiveBayes = 62.19512195121951 %\n",
      "randomForest = 57.3170731707317 %\n",
      "randomForestCVGS = 71.95121951219512 %\n",
      "gbdt = 74.39024390243902 %\n",
      "gbdtCVGS = 68.29268292682927 %\n",
      "lgbm = 69.51219512195121 %\n",
      "lgbmCVGS = 68.29268292682927 %\n",
      "adaBoost = 71.95121951219512 %\n",
      "adaBoostCVGS = 76.82926829268293 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = None\n",
    "Team_B = None\n",
    "featureSel = 3\n",
    "\n",
    "# W/L prediction\n",
    "gamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period, Team_A, Team_B, featureSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions by voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games = 82\n",
      "Number of models = 15\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = adaBoostCVGS w/ the accuracy of 76.82926829268293 %\n",
      "Prediction Accuracy by voting = 73.17073170731707 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = None\n",
    "Team_B = None\n",
    "featureSel = 3\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period, Team_A, Team_B, featureSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions by voting w/ selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games = 82\n",
      "Number of models = 5\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = adaBoostCVGS w/ the accuracy of 76.82926829268293 %\n",
      "Prediction Accuracy by voting = 73.17073170731707 %\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = None\n",
    "Team_B = None\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'supVecMachine': supVecMachine,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'gbdt': gbdt,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSW vs HOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=1(voteForLoss=2, voteForWin=3), Y_truth=1\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=0\n",
      "Y_predict=0(voteForLoss=3, voteForWin=2), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=0\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=1\n",
      "Number of games = 7\n",
      "Number of models = 5\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = gbdt w/ the accuracy of 71.42857142857143 %\n",
      "Prediction Accuracy by voting = 57.14285714285714 %\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'GSW'\n",
    "Team_B = 'HOU'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'supVecMachine': supVecMachine,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'gbdt': gbdt,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=0\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=1\n",
      "Number of games = 7\n",
      "Number of models = 1\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = adaBoostCVGS w/ the accuracy of 71.42857142857143 %\n",
      "Prediction Accuracy by voting = 71.42857142857143 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'GSW'\n",
    "Team_B = 'HOU'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLE vs BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=0\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=0(voteForLoss=5, voteForWin=0), Y_truth=1\n",
      "Number of games = 7\n",
      "Number of models = 5\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = logiRegr w/ the accuracy of 85.71428571428571 %\n",
      "Prediction Accuracy by voting = 85.71428571428571 %\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'CLE'\n",
    "Team_B = 'BOS'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'supVecMachine': supVecMachine,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'gbdt': gbdt,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=0\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=0\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=0(voteForLoss=1, voteForWin=0), Y_truth=1\n",
      "Number of games = 7\n",
      "Number of models = 1\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = adaBoostCVGS w/ the accuracy of 85.71428571428571 %\n",
      "Prediction Accuracy by voting = 85.71428571428571 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'CLE'\n",
    "Team_B = 'BOS'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSW vs CLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=5), Y_truth=1\n",
      "Number of games = 4\n",
      "Number of models = 5\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = logiRegr w/ the accuracy of 100.0 %\n",
      "Prediction Accuracy by voting = 100.0 %\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'GSW'\n",
    "Team_B = 'CLE'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'supVecMachine': supVecMachine,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'gbdt': gbdt,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Y_predict=1(voteForLoss=0, voteForWin=1), Y_truth=1\n",
      "Number of games = 4\n",
      "Number of models = 1\n",
      "---------- Prediction Accuracy ----------\n",
      "Best Model = adaBoostCVGS w/ the accuracy of 100.0 %\n",
      "Prediction Accuracy by voting = 100.0 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = 'GSW'\n",
    "Team_B = 'CLE'\n",
    "featureSel = 3\n",
    "\n",
    "modelsLUTSel = {\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}\n",
    "\n",
    "votingGamePrediction(dfFile, modelsLUTSel, dateStart, dateEnd, period, Team_A, Team_B, featureSel, isReport=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Game Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home/Away_A</th>\n",
       "      <th>Team_A</th>\n",
       "      <th>Team_B</th>\n",
       "      <th>logiRegr</th>\n",
       "      <th>logiRegrCVGS</th>\n",
       "      <th>supVecMachine</th>\n",
       "      <th>supVecMachineCVGS</th>\n",
       "      <th>xgbc</th>\n",
       "      <th>xgbcCVGS</th>\n",
       "      <th>...</th>\n",
       "      <th>randomForest</th>\n",
       "      <th>randomForestCVGS</th>\n",
       "      <th>gbdt</th>\n",
       "      <th>gbdtCVGS</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>lgbmCVGS</th>\n",
       "      <th>adaBoost</th>\n",
       "      <th>adaBoostCVGS</th>\n",
       "      <th>Vote for Win</th>\n",
       "      <th>Vote for Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>GSW</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>1</td>\n",
       "      <td>GSW</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>1</td>\n",
       "      <td>CLE</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-08</td>\n",
       "      <td>1</td>\n",
       "      <td>CLE</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Home/Away_A Team_A Team_B  logiRegr  logiRegrCVGS  \\\n",
       "0  2018-05-31            1    GSW    CLE         1             1   \n",
       "1  2018-06-03            1    GSW    CLE         1             1   \n",
       "2  2018-06-06            1    CLE    GSW         0             0   \n",
       "3  2018-06-08            1    CLE    GSW         0             0   \n",
       "\n",
       "   supVecMachine  supVecMachineCVGS  xgbc  xgbcCVGS      ...        \\\n",
       "0              1                  1     1         1      ...         \n",
       "1              1                  1     1         1      ...         \n",
       "2              0                  0     0         0      ...         \n",
       "3              0                  0     0         0      ...         \n",
       "\n",
       "   randomForest  randomForestCVGS  gbdt  gbdtCVGS  lgbm  lgbmCVGS  adaBoost  \\\n",
       "0             0                 1     1         1     1         0         1   \n",
       "1             0                 1     1         1     1         0         1   \n",
       "2             0                 0     0         0     0         0         0   \n",
       "3             0                 0     0         0     0         0         0   \n",
       "\n",
       "   adaBoostCVGS  Vote for Win  Vote for Loss  \n",
       "0             1            13              2  \n",
       "1             1            13              2  \n",
       "2             0             0             15  \n",
       "3             0             0             15  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "date = ['2018-05-31', '2018-06-03', '2018-06-06', '2018-06-08']\n",
    "period = 5\n",
    "Team_A = ['GSW', 'GSW', 'CLE', 'CLE']\n",
    "Team_B = ['CLE', 'CLE', 'GSW', 'GSW']\n",
    "homeAway = [1, 1, 1, 1]\n",
    "featureSel = 3\n",
    "\n",
    "# W/L prediction\n",
    "i = 0\n",
    "for date, Team_A, Team_B, homeAway in zip(date, Team_A, Team_B, homeAway):\n",
    "    df_single = futureGamePrediction(dfFile, modelsLUT, date, period, Team_A, Team_B, homeAway, featureSel)\n",
    "    if i == 0:\n",
    "        df_all = df_single\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df_single], ignore_index=True)\n",
    "    i += 1\n",
    "\n",
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
